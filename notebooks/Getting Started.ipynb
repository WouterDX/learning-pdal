{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to PDAL\n",
    "Hopefully you've arrived here by starting the Docker container. By doing so, you've already installed the prerequisites and should have no issues stepping through the remainder of the notebooks.\n",
    "\n",
    "We start by importing some packages that are required to download our sample data, and create and execute a simple PDAL pipeline that reads the point cloud into a Numpy `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pdal\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next batch of code is simply to check whether or not we have already downloaded the sample data, and to do so now, if needed. We will be working with some of the ISPRS ground filtering datasets that are hosted in the `PDAL/data` repository on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Found and verified', './samp11-utm.laz')\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/PDAL/data/raw/master/isprs/'\n",
    "last_percent_reported = None\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "pc_filename = maybe_download('samp11-utm.laz', 99563)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create our first, very simply pipeline. It specifies only the path to the input data we wish to read. In later tutorials, we will expand on the pipeline, adding filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json = u'''\n",
    "{\n",
    "  \"pipeline\":[\n",
    "    \"%s\"\n",
    "  ]\n",
    "}''' % pc_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, check that it's valid, and execute it. We check that we have read the expected number of points and number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 38010 points with 12 dimensions\n",
      "Dimension names are (u'X', u'Y', u'Z', u'Intensity', u'ReturnNumber', u'NumberOfReturns', u'ScanDirectionFlag', u'EdgeOfFlightLine', u'Classification', u'ScanAngleRank', u'UserData', u'PointSourceId')\n"
     ]
    }
   ],
   "source": [
    "p = pdal.Pipeline(json)\n",
    "p.validate() # check if our JSON and options were good\n",
    "p.loglevel = 8 #really noisy\n",
    "count = p.execute()\n",
    "data = p.arrays[0]\n",
    "metadata = p.metadata\n",
    "log = p.log\n",
    "print('Read', count, 'points with', len(data.dtype), 'dimensions')\n",
    "print('Dimension names are', data.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
